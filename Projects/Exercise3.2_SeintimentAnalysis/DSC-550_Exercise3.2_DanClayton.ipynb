{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dan Clayton<br>\n",
    "DSC-550 Exercise 3.2<BR>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8196_8</td>\n",
       "      <td>1</td>\n",
       "      <td>I dont know why people think this is such a ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7166_2</td>\n",
       "      <td>0</td>\n",
       "      <td>This movie could have been very good, but come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10633_1</td>\n",
       "      <td>0</td>\n",
       "      <td>I watched this video at a friend's house. I'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>319_1</td>\n",
       "      <td>0</td>\n",
       "      <td>A friend of mine bought this film for £1, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8713_10</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;This movie is full of references. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  sentiment                                             review\n",
       "0   5814_8          1  With all this stuff going down at the moment w...\n",
       "1   2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2   7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3   3630_4          0  It must be assumed that those who praised this...\n",
       "4   9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
       "5   8196_8          1  I dont know why people think this is such a ba...\n",
       "6   7166_2          0  This movie could have been very good, but come...\n",
       "7  10633_1          0  I watched this video at a friend's house. I'm ...\n",
       "8    319_1          0  A friend of mine bought this film for £1, and ...\n",
       "9  8713_10          1  <br /><br />This movie is full of references. ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 1: Using the TextBlob Sentiment Analyzer\n",
    "#Import the movie review data as a data frame and ensure that the data is loaded properly.\n",
    "df = pd.read_csv('labeledTrainData.tsv', sep='\\t')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           review\n",
      "sentiment        \n",
      "0           12500\n",
      "1           12500\n"
     ]
    }
   ],
   "source": [
    "#How many of each positive and negative reviews are there?\n",
    "print(df[['sentiment', 'review']].groupby('sentiment').count())\n",
    "\n",
    "#Conclusion--there are 12,500 positive and 12,500 negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install texblob package\n",
    "import sys\n",
    "#!{sys.executable} -m pip install -U textblob\n",
    "#!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use TextBlob to classify each movie review as positive or negative. \n",
    "#Assume that a polarity score greater than or equal to zero is a positive sentiment and less than 0 is a negative sentiment.\n",
    "\n",
    "#Returns a 1 for positive moview review, 0 for negative movie review\n",
    "def get_sentiment(movie_review):\n",
    "    #Build a text blobl of the movie review\n",
    "    review = TextBlob(movie_review)\n",
    "    \n",
    "    #Calculate the sentiment\n",
    "    review.sentiment\n",
    "    \n",
    "    #If the sentiment is >= 0 then positive, else return negative\n",
    "    if review.sentiment.polarity >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Use the previously defined function to populate the sentiment as provided by textblob\n",
    "df['blob_sentiment'] = df['review'].apply(get_sentiment)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68524\n"
     ]
    }
   ],
   "source": [
    "#Check the accuracy of this model. Is this model better than random guessing?\n",
    "print(len(df[df['sentiment']==df['blob_sentiment']])/len(df))\n",
    "\n",
    "#Yes--blob sentiment was correct 68.5% of the time--better than 50/50 random guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\dancl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#For up to five points extra credit, use another prebuilt text sentiment analyzer, e.g., VADER, and repeat steps (3) and (4).\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize # Passing the string text into word tokenize for bre\n",
    "\n",
    "\n",
    "\n",
    "def get_vader_sentiment(review):\n",
    "    #Create an empty sentiment analyzer\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    #Calculate the sentiment for this review\n",
    "    sentiment_dict = sid_obj.polarity_scores(review)\n",
    "    \n",
    "    if sentiment_dict['compound'] >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#print(get_vader_sentiment(df['review'].iloc[0]))\n",
    "\n",
    "#Populate the vader sentiment using the function defined above\n",
    "df['vader_sentiment'] = df['review'].apply(get_vader_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69216\n"
     ]
    }
   ],
   "source": [
    "#Check to see how accurate the vader sentiment was:\n",
    "print(len(df[df['sentiment']==df['vader_sentiment']])/len(df))\n",
    "\n",
    "#At 69.2% the Vader sentiment was slightly more accurate than the blob sentiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Prepping Text for a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all text to lowercase letters.\n",
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation and special characters from the text.\n",
    "#df['review'] = df['review'].str.extract('(\\w+)', expand = False)\n",
    "df['review'] = df['review'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dancl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dancl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Remove stop words.\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "#Function to remove stop words from the string given\n",
    "def rem_stops(txt):\n",
    "    text_tokens = word_tokenize(txt)\n",
    "    return [w for w in text_tokens if not w.lower() in stop_words]\n",
    "    #return [word for word in text_tokens if not word in stopwords.words()]\n",
    "\n",
    "#Remove all the stop words from the reviews\n",
    "df['review'] = df['review'].apply(rem_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply NLTK’s PorterStemmer.\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def get_singles(txt):\n",
    "    return [stemmer.stem(plural) for plural in txt]\n",
    "\n",
    "df['review'] = df['review'].apply(get_singles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "#Create a bag-of-words matrix from your stemmed text (output from (4)), where each row is a word-count vector \n",
    "#for a single movie review (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook). \n",
    "#Display the dimensions of your bag-of-words matrix. The number of rows in this matrix should be the same as \n",
    "#the number of rows in your original data frame.\n",
    "\n",
    "#df['review'].head(10)\n",
    "\n",
    "#Import the neccesary library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Instantiate the vectorizer object\n",
    "count = CountVectorizer()\n",
    "\n",
    "def get_word_vector(review):\n",
    "    #bag of words object\n",
    "    bow = count.fit_transform(review)\n",
    "    return bow.toarray()\n",
    "\n",
    "#Blank dataframe on which to append the word vectors\n",
    "#df1 = pd.DataFrame()\n",
    "\n",
    "#Populate the sparse arrays in the dataframe\n",
    "df['bow'] = df['review'].apply(get_word_vector)\n",
    "\n",
    "#Check the size of the sparse array (actually a dataframe--converted to array below)\n",
    "print(len(df['bow']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array length:  25000\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Convert dataframe into series\n",
    "s = pd.Series(df['bow'])\n",
    "\n",
    "#Create an array from the series\n",
    "df_array = np.array(s)\n",
    "\n",
    "#Show the array stats\n",
    "print('Array length: ', len(df_array))\n",
    "print(type(df_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a term frequency-inverse document frequency (tf-idf) matrix from your stemmed text, for your movie \n",
    "#reviews (see section 6.9 in the Machine Learning with Python Cookbook). \n",
    "#Display the dimensions of your tf-idf matrix. These dimensions should be the same as your bag-of-words matrix.\n",
    "\n",
    "#Import the needed library\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Create the feature matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "def get_fmatrix(txt):\n",
    "    return tfidf.fit_transform(txt)\n",
    "\n",
    "df['f_matrix'] = df['review'].apply(get_fmatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array length:  25000\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Converting the dataframe to an array, per the instructions\n",
    "#Convert dataframe into series\n",
    "s = pd.Series(df['f_matrix'])\n",
    "\n",
    "#Create an array from the series\n",
    "fm_array = np.array(s)\n",
    "\n",
    "#Show the array stats\n",
    "print('Array length: ', len(fm_array))\n",
    "print(type(fm_array))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
